name: "Phi 3 mini 4k"
full_name: "microsoft/Phi-3-mini-4k-instruct"
description: "Microsoft's Phi-3-mini-4k model running on Text Generation Inference (TGI). A compact yet powerful model optimized for reasoning, coding, and structured tasks."

specs:
  context_window: 4096
  model_type: "Transformer"
  version: "1.0"

strengths:
  - "Code generation"
  - "Step-by-step reasoning"
  - "Mathematical problems"
  - "Technical explanations"

use_cases:
  - name: "Code Generation"
    description: "Writing and debugging code with detailed comments"
  - name: "Mathematical Problems"
    description: "Solving complex math problems step by step"
  - name: "Technical Writing"
    description: "Explaining complex concepts clearly"
  - name: "Logical Reasoning"
    description: "Breaking down problems into logical steps"

configuration:
  model_name: "phi-3-mini-4k-tgi"
  model_id: "microsoft/Phi-3-mini-4k-instruct"
  tgi_version: "2.4.0-intel-xpu"
  port: 8081
  parameters:
    shm_size: "2g"
    max_concurrent_requests: 1
    max_batch_size: 1
    max_total_tokens: 4096
    max_input_length: 2048
    max_waiting_tokens: 10

examples:
  - name: "Code Generation"
    description: "Generate a factorial function with comments"
    code: |
      curl -X POST http://localhost:8081/generate \
        -H 'Content-Type: application/json' \
        -d '{
          "inputs": "Write a Python function that calculates the factorial of a number. Include comments explaining the logic:",
          "parameters": {
            "max_new_tokens": 150,
            "temperature": 0.2
          }
        }'

  - name: "Math Problem"
    description: "Solve a discount and tax calculation"
    code: |
      curl -X POST http://localhost:8081/generate \
        -H 'Content-Type: application/json' \
        -d '{
          "inputs": "Solve step by step: A store offers a 15% discount on a $80 item. What is the final price after tax if the tax rate is 8%?",
          "parameters": {
            "max_new_tokens": 200,
            "temperature": 0.1
          }
        }'

best_practices:
  - "Use temperature 0.1-0.2 for code and math tasks"
  - "Include 'step by step' for complex problems"
  - "Break down complex queries into smaller steps"
  - "Specify programming language and requirements for code tasks"

deployment:
  repository: "https://github.com/rahulunair/xpu_tgi"
  steps:
    - name: "Clone Repository"
      command: "git clone https://github.com/rahulunair/xpu_tgi.git"
    - name: "Generate Token"
      command: "python utils/generate_token.py"
    - name: "Start Model"
      command: "./start.sh Phi3-4k"

hardware:
  - name: "Intel Data Center Max GPU"
    memory: "48GB"
    requirements: "Single GPU configuration" 