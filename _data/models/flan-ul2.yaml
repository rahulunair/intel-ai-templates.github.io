name: flan-ul2
title: Flan-UL2
model_id: google/flan-ul2
description: "Google's Flan-UL2 model running on Text Generation Inference (TGI) on Intel XPU. Flan-UL2 excels at instruction-following tasks like translation, summarization, and question answering."

license_notice: "Before using this model, please review the license terms and usage rights on the Hugging Face model page. Ensure your use case complies with the model's terms of use and check for any commercial usage restrictions."

# TGI specific configuration
tgi: true
architecture_diagram: |
  flowchart LR
      Client([Client])
      Traefik[Traefik Proxy]
      Auth[Auth Service]
      TGI[TGI Service]

      Client --> Traefik
      Traefik --> Auth
      Auth --> Traefik
      Traefik --> TGI
      TGI --> Traefik
      Traefik --> Client

      subgraph Internal["Internal Network"]
          Traefik
          Auth
          TGI
      end

key_features:
  - "üîí Token-based authentication with automatic ban after failed attempts"
  - "üö¶ Rate limiting (global: 10 req/s, per-IP: 10 req/s)"
  - "üõ°Ô∏è Security headers and IP protection"
  - "üîÑ Health monitoring and automatic recovery"
  - "üöÄ Optimized for Intel GPUs"

# Model specific information
context_window: "4096 tokens"
strengths:
  - "Instruction following"
  - "Translation tasks"
  - "Text summarization"
  - "Structured responses"

use_cases:
  - "Language translation"
  - "Text summarization"
  - "Question answering"
  - "Classification tasks"

configuration: |
  MODEL_NAME=flan-ul2-tgi
  MODEL_ID=google/flan-ul2
  TGI_VERSION=2.4.0-intel-xpu
  PORT=8083
  SHM_SIZE=8g
  MAX_CONCURRENT_REQUESTS=10
  MAX_BATCH_SIZE=1
  MAX_TOTAL_TOKENS=4096
  MAX_INPUT_LENGTH=2039
  MAX_WAITING_TOKENS=20

deployment_steps:
  - title: "Create Account"
    description: "Create a standard account on Intel Tiber AI Cloud"
    link: "https://cloud.intel.com"
    link_text: "Visit Intel Cloud Portal"

  - title: "Select Hardware"
    description: "Select an Intel Data Center Max Series GPU VM"

  - title: "Clone Repository"
    description: "Clone the TGI repository"
    code: "git clone https://github.com/tiberaicommunity/xpu_tgi"

  - title: "Generate Token"
    description: "Generate authentication token for secure access"
    code: "python utils/generate_token.py"

  - title: "Start Model"
    description: "Start the FLAN-UL2 model"
    code: "./start.sh flan-ul2"

  - title: "Test Model"
    description: "Make a test request to verify deployment"
    code: |
      curl -X POST http://localhost:8083/generate \
        -H "Authorization: Bearer YOUR_TOKEN" \
        -H "Content-Type: application/json" \
        -d '{"inputs": "Summarize this text: The quick brown fox jumps over the lazy dog.", "parameters": {"max_new_tokens": 50}}'

# Tags for filtering
tags:
  - label: "Transformer"
    color: "#3B82F6"
  - label: "4K context"
    color: "#10B981"
  - label: "Instruction"
    color: "#8B5CF6"
  - label: "TGI"
    color: "#EF4444"
  - label: "Google"
    color: "#34D399"
  - label: "Translation"
    color: "#F472B6" 