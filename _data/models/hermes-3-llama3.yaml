name: hermes-3-llama3
title: Hermes-3 LLaMA 3.1
model_id: NousResearch/Hermes-3-llama3.1
description: "NousResearch's Hermes-3 based on Llama3.1 running on Text Generation Inference (TGI). An advanced model offering improved reasoning, coding, and general task performance."

license_notice: "Before using this model, please review the license terms and usage rights on the Hugging Face model page."

# TGI specific configuration
tgi: true
architecture_diagram: |
  flowchart LR
      Client([Client])
      Traefik[Traefik Proxy]
      Auth[Auth Service]
      TGI[TGI Service]

      Client --> Traefik
      Traefik --> Auth
      Auth --> Traefik
      Traefik --> TGI
      TGI --> Traefik
      Traefik --> Client

      subgraph Internal["Internal Network"]
          Traefik
          Auth
          TGI
      end

key_features:
  - "üîí Token-based authentication with automatic ban after failed attempts"
  - "üö¶ Rate limiting (global: 10 req/s, per-IP: 10 req/s)"
  - "üõ°Ô∏è Security headers and IP protection"
  - "üîÑ Health monitoring and automatic recovery"
  - "üöÄ Optimized for Intel GPUs"

# Model specific information
context_window: "8192 tokens"
strengths:
  - "Advanced reasoning"
  - "Code generation"
  - "Complex analysis"
  - "Multi-step reasoning"

use_cases:
  - "Complex problem solving"
  - "Code generation and analysis"
  - "Detailed explanations"
  - "Multi-step reasoning tasks"

configuration: |
  MODEL_NAME=hermes-3-llama3.1-tgi
  MODEL_ID=NousResearch/Hermes-3-llama3.1
  TGI_VERSION=2.4.0-intel-xpu
  PORT=8085
  SHM_SIZE=2g
  MAX_CONCURRENT_REQUESTS=1
  MAX_BATCH_SIZE=1
  MAX_TOTAL_TOKENS=8192
  MAX_INPUT_LENGTH=4096
  MAX_WAITING_TOKENS=10

# Tags for filtering
tags:
  - label: "Transformer"
    color: "#3B82F6"
  - label: "8K context"
    color: "#10B981"
  - label: "Instruction"
    color: "#8B5CF6"
  - label: "TGI"
    color: "#EF4444"
  - label: "LLaMA"
    color: "#F59E0B" 