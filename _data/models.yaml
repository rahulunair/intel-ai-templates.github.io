models:
  - name: "Phi 3 mini 4k"
    category: "LLM"
    description: "Compact 4k context window language model optimized for instruction following and chat"
    hardware:
      - "Intel Data Center Max GPU (48GB)"
    tags:
      - type: "architecture"
        label: "Transformer"
        color: "#3B82F6"
      - type: "size"
        label: "4K context"
        color: "#10B981"
      - type: "type"
        label: "Instruction"
        color: "#8B5CF6"
    license: "MIT"
    use_cases:
      - "Text generation"
      - "Chat applications"
      - "Code completion"
    port: 8089
    model_id: "microsoft/Phi-3-mini-4k-instruct"

  - name: "Phi 3 mini 128k"
    category: "LLM"
    description: "Extended context window variant of Phi 3 supporting up to 128k tokens"
    hardware:
      - "Intel Data Center Max GPU (48GB)"
    tags:
      - type: "architecture"
        label: "Transformer"
        color: "#3B82F6"
      - type: "size"
        label: "128K context"
        color: "#EF4444"
      - type: "type"
        label: "Long Context"
        color: "#F59E0B"
    license: "MIT"
    use_cases:
      - "Document analysis"
      - "Long form content generation"
      - "Code analysis"
    port: 8090
    model_id: "microsoft/Phi-3-mini-128k"

  - name: "OpenHermes Mistral"
    category: "LLM"
    description: "Open source chat model based on Mistral architecture"
    hardware:
      - "Intel Data Center Max GPU (48GB)"
    tags:
      - type: "architecture"
        label: "Mistral"
        color: "#EC4899"
      - type: "type"
        label: "Chat"
        color: "#14B8A6"
    license: "Apache 2.0"
    use_cases:
      - "Conversational AI"
      - "Task assistance"
      - "Knowledge QA"
    port: 8091
    model_id: "teknium/OpenHermes-Mistral"
